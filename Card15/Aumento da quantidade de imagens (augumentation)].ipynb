{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-22T23:32:12.146916Z",
     "start_time": "2024-11-22T23:32:06.206722Z"
    }
   },
   "source": [
    "# Importa o módulo principal do Keras, uma API de alto nível para criação de redes neurais.\n",
    "# Em versões modernas, Keras está integrado ao TensorFlow.\n",
    "import keras\n",
    "\n",
    "# Importa o TensorFlow, uma biblioteca amplamente usada para aprendizado profundo e computação numérica.\n",
    "# Ele serve como backend para Keras, fornecendo as operações de baixo nível necessárias.\n",
    "import tensorflow as tf\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T23:32:12.179385Z",
     "start_time": "2024-11-22T23:32:12.149924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importa o conjunto de dados MNIST, que contém imagens de dígitos escritos à mão (0-9).\n",
    "# Este conjunto de dados é amplamente utilizado em tarefas de classificação de imagens.\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Importa a classe `Sequential` para criar modelos de rede neural sequenciais (camada a camada).\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Importa diversas camadas utilizadas em redes neurais:\n",
    "# - InputLayer: Define a camada de entrada.\n",
    "# - Dense: Camada totalmente conectada.\n",
    "# - Flatten: Transforma entradas multidimensionais em vetores.\n",
    "# - Conv2D: Camada de convolução para processamento de imagens.\n",
    "# - MaxPooling2D: Camada de pooling para redução dimensional.\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "# Importa a classe `ImageDataGenerator`, usada para realizar aumento de dados (data augmentation).\n",
    "# O aumento de dados gera versões transformadas (rotacionadas, ampliadas, etc.) das imagens,\n",
    "# ajudando a melhorar a generalização do modelo.\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Importa o módulo `utils` do Keras, com alias `np_utils`, que fornece ferramentas úteis,\n",
    "# como a função `to_categorical` para converter rótulos em formato one-hot.\n",
    "from tensorflow.keras import utils as np_utils\n"
   ],
   "id": "960d3a768eed8dd1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T23:32:13.329496Z",
     "start_time": "2024-11-22T23:32:13.064317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Carrega o conjunto de dados MNIST.\n",
    "# `mnist.load_data()` retorna duas tuplas:\n",
    "# - `(X_treinamento, y_treinamento)`: Dados de treinamento (imagens e rótulos correspondentes).\n",
    "# - `(X_teste, y_teste)`: Dados de teste (imagens e rótulos correspondentes).\n",
    "# As imagens são representadas como arrays NumPy com formato (28, 28), contendo valores de intensidade de pixels (0 a 255).\n",
    "(X_treinamento, y_treinamento), (X_teste, y_teste) = mnist.load_data()\n"
   ],
   "id": "132099c5684905c9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T23:32:16.790795Z",
     "start_time": "2024-11-22T23:32:16.679338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Redimensiona os dados de treinamento para incluir um canal adicional (28x28x1),\n",
    "# necessário para processamento em redes convolucionais que esperam entradas com 3 ou 4 dimensões.\n",
    "# `X_treinamento.shape[0]` é o número total de exemplos no conjunto de treinamento.\n",
    "X_treinamento = X_treinamento.reshape(X_treinamento.shape[0], 28, 28, 1)\n",
    "\n",
    "# Redimensiona os dados de teste para o mesmo formato (28x28x1).\n",
    "X_teste = X_teste.reshape(X_teste.shape[0], 28, 28, 1)\n",
    "\n",
    "# Converte os valores dos pixels das imagens de inteiros (`uint8`) para ponto flutuante (`float32`).\n",
    "# Isso é necessário para normalizar os valores.\n",
    "X_treinamento = X_treinamento.astype('float32')\n",
    "X_teste = X_teste.astype('float32')\n",
    "\n",
    "# Normaliza os valores dos pixels para o intervalo [0, 1].\n",
    "# Isso melhora a estabilidade numérica durante o treinamento.\n",
    "X_treinamento /= 255\n",
    "X_teste /= 255\n",
    "\n",
    "# Converte os rótulos de inteiros (0-9) para o formato one-hot encoding.\n",
    "# Em vez de um único valor para cada rótulo, cria-se um vetor binário de comprimento 10.\n",
    "# Exemplo: O rótulo 3 é transformado em [0, 0, 0, 1, 0, 0, 0, 0, 0, 0].\n",
    "y_treinamento = np_utils.to_categorical(y_treinamento, 10)\n",
    "y_teste = np_utils.to_categorical(y_teste, 10)\n"
   ],
   "id": "4331e1481638d3e9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T23:32:32.024792Z",
     "start_time": "2024-11-22T23:32:31.960168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cria um modelo sequencial, onde as camadas são empilhadas uma após a outra.\n",
    "classificador = Sequential()\n",
    "\n",
    "# Adiciona uma camada de entrada para processar imagens no formato 28x28x1 (grayscale).\n",
    "classificador.add(InputLayer(shape=(28, 28, 1)))\n",
    "\n",
    "# Adiciona uma camada convolucional 2D com:\n",
    "# - 32 filtros, cada um de tamanho 3x3.\n",
    "# - Função de ativação 'relu', que introduz não-linearidade.\n",
    "# Essa camada aprende características locais, como bordas e texturas.\n",
    "classificador.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# Adiciona uma camada de max pooling com uma janela de 2x2.\n",
    "# Essa camada reduz a dimensionalidade das representações aprendidas,\n",
    "# ajudando a reduzir o custo computacional e evitar overfitting.\n",
    "classificador.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Achata a saída das camadas anteriores, transformando a matriz em um vetor unidimensional.\n",
    "# Isso é necessário antes de conectar as camadas densas.\n",
    "classificador.add(Flatten())\n",
    "\n",
    "# Adiciona uma camada totalmente conectada (densa) com 128 neurônios e ativação 'relu'.\n",
    "# Essa camada aprende representações mais abstratas e complexas.\n",
    "classificador.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "# Adiciona a camada de saída com 10 neurônios (um para cada classe) e ativação 'softmax'.\n",
    "# A função 'softmax' converte os valores de saída em probabilidades, somando 1.\n",
    "classificador.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# Compila o modelo especificando:\n",
    "# - `loss='categorical_crossentropy'`: Função de perda para classificação multiclasse com rótulos one-hot.\n",
    "# - `optimizer='adam'`: Algoritmo de otimização que ajusta os pesos durante o treinamento.\n",
    "# - `metrics=['accuracy']`: Métrica de avaliação que monitora a precisão durante o treinamento e validação.\n",
    "classificador.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ],
   "id": "2539563c57db02a2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T23:33:24.671051Z",
     "start_time": "2024-11-22T23:33:24.665718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cria um objeto `ImageDataGenerator` para realizar aumento de dados (data augmentation).\n",
    "# O aumento de dados gera versões transformadas das imagens, ajudando a melhorar a generalização do modelo,\n",
    "# especialmente quando o conjunto de dados é pequeno ou quando queremos evitar overfitting.\n",
    "\n",
    "gerador_treinamento = ImageDataGenerator(\n",
    "    rotation_range=7,         # Gira as imagens aleatoriamente em até 7 graus.\n",
    "    horizontal_flip=True,     # Permite a inversão horizontal aleatória das imagens.\n",
    "    shear_range=0.2,          # Aplica cisalhamento aleatório em até 20%.\n",
    "    height_shift_range=0.07,  # Desloca as imagens verticalmente em até 7% da altura.\n",
    "    zoom_range=0.2            # Aplica zoom aleatório em até 20% das imagens.\n",
    ")\n"
   ],
   "id": "d648b4285b964b18",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T23:35:28.557911Z",
     "start_time": "2024-11-22T23:35:28.552137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cria um objeto `ImageDataGenerator` para o conjunto de dados de teste.\n",
    "# No caso do conjunto de teste, normalmente não aplicamos aumento de dados, \n",
    "# pois queremos avaliar o modelo em dados não modificados.\n",
    "# Portanto, o `ImageDataGenerator` é instanciado sem nenhuma transformação.\n",
    "gerador_teste = ImageDataGenerator()\n"
   ],
   "id": "91c7137dfa60851b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T23:35:28.564911Z",
     "start_time": "2024-11-22T23:35:28.559919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cria um gerador de dados para o conjunto de treinamento utilizando o `ImageDataGenerator` definido anteriormente.\n",
    "# O método `flow` gera batches de imagens e rótulos, realizando o aumento de dados em tempo real.\n",
    "# - `X_treinamento`: Dados de entrada (imagens) para o treinamento.\n",
    "# - `y_treinamento`: Rótulos correspondentes às imagens.\n",
    "# - `batch_size=128`: Número de amostras por batch durante o treinamento.\n",
    "# Esse gerador será usado para alimentar o modelo durante o treinamento, aplicando as transformações definidas no `gerador_treinamento`.\n",
    "base_treinamento = gerador_treinamento.flow(X_treinamento, y_treinamento, batch_size=128)\n"
   ],
   "id": "999989d67cc049a9",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T23:33:37.079322Z",
     "start_time": "2024-11-22T23:33:37.074016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cria um gerador de dados para o conjunto de teste utilizando o `ImageDataGenerator` definido anteriormente.\n",
    "# O método `flow` gera batches de imagens e rótulos para o conjunto de teste, mas sem aplicar aumentos de dados,\n",
    "# já que o conjunto de teste não deve ser alterado para avaliação do modelo.\n",
    "# - `X_teste`: Dados de entrada (imagens) para o teste.\n",
    "# - `y_teste`: Rótulos correspondentes às imagens.\n",
    "# - `batch_size=128`: Número de amostras por batch durante a avaliação.\n",
    "# Esse gerador será usado para alimentar o modelo durante a avaliação ou validação.\n",
    "base_teste = gerador_teste.flow(X_teste, y_teste, batch_size=128)\n"
   ],
   "id": "cde407f6217f667",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T23:36:58.474657Z",
     "start_time": "2024-11-22T23:35:31.033293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Treina o modelo utilizando o gerador de dados para o conjunto de treinamento.\n",
    "# O método `fit` recebe os geradores de dados em vez de arrays diretos, permitindo o uso do aumento de dados em tempo real.\n",
    "# - `base_treinamento`: Gerador que fornece os dados de treinamento com aumento de dados.\n",
    "# - `epochs=5`: Número de épocas (iterações completas sobre o conjunto de treinamento).\n",
    "# - `validation_data=base_teste`: Conjunto de dados para validação, neste caso o gerador para o conjunto de teste.\n",
    "# O modelo será treinado por 5 épocas e, a cada época, a precisão será calculada no conjunto de teste usando `base_teste`.\n",
    "classificador.fit(base_treinamento, epochs=5, validation_data=base_teste)\n"
   ],
   "id": "6540423c2c4c2d50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001B[1m469/469\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 39ms/step - accuracy: 0.9639 - loss: 0.1157 - val_accuracy: 0.9746 - val_loss: 0.0800\n",
      "Epoch 2/5\n",
      "\u001B[1m469/469\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 38ms/step - accuracy: 0.9657 - loss: 0.1100 - val_accuracy: 0.9761 - val_loss: 0.0732\n",
      "Epoch 3/5\n",
      "\u001B[1m469/469\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 36ms/step - accuracy: 0.9692 - loss: 0.0988 - val_accuracy: 0.9686 - val_loss: 0.0981\n",
      "Epoch 4/5\n",
      "\u001B[1m469/469\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 36ms/step - accuracy: 0.9698 - loss: 0.0972 - val_accuracy: 0.9800 - val_loss: 0.0623\n",
      "Epoch 5/5\n",
      "\u001B[1m469/469\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 35ms/step - accuracy: 0.9714 - loss: 0.0894 - val_accuracy: 0.9748 - val_loss: 0.0754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x15b4ae02690>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5661af8f68cd696d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
