{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Train / Test\n",
    "Começaremos criando algum conjunto de dados para o qual queremos construir um modelo (neste caso, uma regressão polinomial):"
   ],
   "id": "7d3f84a609d9bc0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T18:13:06.772232Z",
     "start_time": "2024-10-21T18:13:06.724346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importa a funcionalidade inline para exibir gráficos diretamente no Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Importa o pacote NumPy e as funções do Pylab para manipulação de dados e criação de gráficos\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "\n",
    "# Define uma semente para o gerador de números aleatórios (garante que os resultados sejam reproduzíveis)\n",
    "np.random.seed(2)\n",
    "\n",
    "# Gera 100 valores de velocidades de página, distribuídos normalmente com média 3.0 e desvio padrão 1.0\n",
    "pageSpeeds = np.random.normal(3.0, 1.0, 100)\n",
    "\n",
    "# Gera 100 valores para a quantidade de compra, também distribuídos normalmente, com média 50 e desvio padrão 30\n",
    "# Em seguida, divide cada valor gerado pela respectiva velocidade de página, criando uma relação inversa\n",
    "purchaseAmount = np.random.normal(50.0, 30.0, 100) / pageSpeeds\n",
    "\n",
    "# Cria um gráfico de dispersão entre as variáveis 'pageSpeeds' (velocidade de página) e 'purchaseAmount' (quantidade de compra)\n",
    "scatter(pageSpeeds, purchaseAmount)\n"
   ],
   "id": "ae48fbea2e13cf29",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x27d56a69250>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Agora vamos dividir os dados em dois - 80% deles serão usados ​​para “treinar” nosso modelo e os outros 20% para testá-lo. Dessa forma, podemos evitar o overfitting.",
   "id": "4a4a65cdf1f8e92f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
